{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eada1d43",
   "metadata": {},
   "source": [
    "# Kafka Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea47b0ee",
   "metadata": {},
   "source": [
    "## What is the primary purpose of Kafka Connect?\n",
    "\n",
    "- Move data within Kafka clusters\n",
    "- Move data in and out of Kafka without writing code ***\n",
    "- Provide a REST API for producing messages\n",
    "- Perform stream processing using Kafka Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e3b73",
   "metadata": {},
   "source": [
    "## Which of the following is **not** a valid Kafka Connect mode?\n",
    "\n",
    "- Standalone\n",
    "- Distributed\n",
    "- Clustered\n",
    "- Mirrored ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae62c6c",
   "metadata": {},
   "source": [
    "## In standalone mode, connectors run:\n",
    "\n",
    "- On multiple brokers in the Kafka cluster\n",
    "- Across distributed systems automatically\n",
    "- In a single worker process ***\n",
    "- Using Docker containers only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf355ac6",
   "metadata": {},
   "source": [
    "## What are the two types of connectors in Kafka Connect?\n",
    "\n",
    "- Consumer and Producer\n",
    "- Source and Sink ***\n",
    "- Reader and Writer\n",
    "- Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8d9f3",
   "metadata": {},
   "source": [
    "## What does the `plugin.path` configuration do?\n",
    "\n",
    "- Specifies the Kafka topic to use\n",
    "- Sets the REST endpoint for Kafka Connect\n",
    "- Tells Kafka Connect where to find connector JARs ***\n",
    "- Enables schema validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db00116",
   "metadata": {},
   "source": [
    "## What is the role of the `value.converter` setting in a connector configuration?\n",
    "\n",
    "- Defines the Kafka topic used\n",
    "- Specifies how message values are serialized/deserialized ***\n",
    "- Sets how often to poll the source\n",
    "- Specifies the type of connector (source/sink)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc2e40",
   "metadata": {},
   "source": [
    "## Which connector class is used to pull data from a PostgreSQL database?\n",
    "\n",
    "- org.apache.kafka.connect.file.FileStreamSource\n",
    "- org.apache.kafka.connect.storage.StringConverter\n",
    "- io.confluent.connect.jdbc.JdbcSourceConnector ***\n",
    "- kafka.connect.json.JsonConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5876332e",
   "metadata": {},
   "source": [
    "## What is the effect of setting `mode=incrementing` in a JDBC source connector?\n",
    "\n",
    "- It loads the entire table every time\n",
    "- Tracks changes using a timestamp column\n",
    "- Fetches only new rows using a monotonically increasing column ***\n",
    "- Disables polling of the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c785d45",
   "metadata": {},
   "source": [
    "## Which connector would you use to archive Kafka data to AWS S3?\n",
    "\n",
    "- FileStreamSink\n",
    "- JDBC Sink\n",
    "- S3 Sink ***\n",
    "- MongoDB Sink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91610178",
   "metadata": {},
   "source": [
    "## Which of the following is a **valid reason** to use Kafka Connect?\n",
    "\n",
    "- To reduce the need for external storage systems\n",
    "- To debug stream processing applications\n",
    "- To integrate Kafka with external systems using minimal code ***\n",
    "- To analyze data directly within Kafka topics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
